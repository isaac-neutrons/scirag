# SciRAG MCP Server Specification

## Overview

SciRAG provides a Model Context Protocol (MCP) server for document retrieval and storage using vector search. It enables semantic search over document collections stored in RavenDB with embeddings generated by configurable LLM services (Ollama or Gemini).

## Connection Details

- **Transport**: SSE (Server-Sent Events)
- **Default Host**: `0.0.0.0`
- **Default Port**: `8001`
- **Endpoint**: `http://localhost:8001/sse`

## Available Tools

### 1. `retrieve_document_chunks`

Searches the document knowledge base for text chunks semantically similar to a query.

**Parameters:**
| Name | Type | Required | Default | Description |
|------|------|----------|---------|-------------|
| `query` | `string` | Yes | - | The search query text |
| `top_k` | `integer` | No | `5` | Number of top results to return |
| `collection` | `string \| null` | No | `null` | Collection name to filter by. If `null`, searches all collections |

**Returns:** `list[dict]`

Each result dict contains:
```json
{
  "text": "The chunk text content...",
  "source_filename": "document.pdf",
  "chunk_index": 0,
  "score": 0.89,
  "metadata": {
    "file_size": 12345,
    "page_count": 10,
    "creation_date": 1234567890.0,
    "modification_date": 1234567890.0,
    "ingestion_date": 1234567890.0,
    "title": "Document Title",
    "author": "Author Name"
  }
}
```

**Example Call:**
```python
result = await mcp_client.call_tool(
    "retrieve_document_chunks",
    {
        "query": "What are the effects of temperature on reaction rates?",
        "top_k": 3,
        "collection": "research-papers"
    }
)
```

---

### 2. `store_document_chunks`

Stores document chunks in the vectorstore. Automatically generates embeddings for each chunk's text.

**Parameters:**
| Name | Type | Required | Default | Description |
|------|------|----------|---------|-------------|
| `chunks` | `list[dict]` | Yes | - | List of chunk dictionaries (see format below) |
| `collection` | `string` | No | `"DocumentChunks"` | Collection name to store chunks in |

**Chunk Dictionary Format:**
```json
{
  "text": "The text content of this chunk (required)",
  "source_filename": "original_document.pdf (required)",
  "chunk_index": 0,  // required, integer
  "metadata": {      // optional
    "file_size": 12345,
    "page_count": 10,
    "creation_date": 1234567890.0,
    "modification_date": 1234567890.0,
    "title": "Document Title",
    "author": "Author Name"
  }
}
```

**Returns:** `dict`
```json
{
  "success": true,
  "chunks_stored": 15,
  "collection": "research-papers",
  "message": "Successfully stored 15 chunks"
}
```

**Error Response:**
```json
{
  "success": false,
  "chunks_stored": 0,
  "collection": "research-papers",
  "message": "Validation error: Chunk 3 missing required field 'text'"
}
```

**Example Call:**
```python
chunks = [
    {
        "text": "First paragraph of the document...",
        "source_filename": "paper.pdf",
        "chunk_index": 0,
        "metadata": {"page_count": 5, "author": "Smith et al."}
    },
    {
        "text": "Second paragraph continues...",
        "source_filename": "paper.pdf",
        "chunk_index": 1,
        "metadata": {"page_count": 5, "author": "Smith et al."}
    }
]

result = await mcp_client.call_tool(
    "store_document_chunks",
    {
        "chunks": chunks,
        "collection": "research-papers"
    }
)
```

---

### 3. `list_collections`

Lists all available document collections in the vectorstore.

**Parameters:** None

**Returns:** `list[string]`
```json
["DocumentChunks", "research-papers", "lab-notes", "protocols"]
```

Returns an empty list if no collections exist or on error.

**Example Call:**
```python
collections = await mcp_client.call_tool("list_collections", {})
```

---

## Python Client Example

Using the `mcp` library:

```python
import asyncio
from mcp import ClientSession
from mcp.client.sse import sse_client

async def main():
    async with sse_client("http://localhost:8001/sse") as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()
            
            # List available collections
            collections = await session.call_tool("list_collections", {})
            print(f"Available collections: {collections}")
            
            # Search for documents
            results = await session.call_tool(
                "retrieve_document_chunks",
                {
                    "query": "How does enzyme activity change with pH?",
                    "top_k": 5,
                    "collection": "research-papers"
                }
            )
            
            for chunk in results:
                print(f"[{chunk['score']:.2f}] {chunk['source_filename']}: {chunk['text'][:100]}...")

asyncio.run(main())
```

---

## Environment Variables

The MCP server reads these environment variables:

| Variable | Default | Description |
|----------|---------|-------------|
| `RAVENDB_URL` | `http://localhost:8080` | RavenDB server URL |
| `RAVENDB_DATABASE` | `scirag` | Database name |
| `LLM_SERVICE` | `ollama` | LLM service for embeddings (`ollama` or `gemini`) |
| `OLLAMA_URL` | `http://localhost:11434` | Ollama server URL |
| `EMBEDDING_MODEL` | `nomic-embed-text` | Model for generating embeddings |
| `GEMINI_API_KEY` | - | API key for Gemini (if using Gemini service) |
| `LOG_LEVEL` | `DEBUG` | Logging level |

---

## Error Handling

- **`retrieve_document_chunks`**: Raises `ValueError` on errors. Client should catch exceptions.
- **`store_document_chunks`**: Returns a dict with `success: false` on errors. Check the `success` field.
- **`list_collections`**: Returns empty list `[]` on errors. Does not raise exceptions.

---

## Notes

1. **Embeddings**: The server generates embeddings automatically when storing chunks. Clients only need to provide text content.

2. **Collection Names**: Collections are case-sensitive. Use consistent naming.

3. **Chunk Size**: The server accepts chunks of any size. For optimal search results, chunks of ~500 words with ~50 word overlap are recommended.

4. **Concurrent Requests**: The server handles concurrent requests. Each request creates a fresh database connection.

5. **Transport**: Currently only SSE transport is supported. The server runs as an HTTP server.
